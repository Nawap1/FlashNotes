{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nawap Bastola\\AppData\\Local\\Temp\\ipykernel_2828\\617962864.py:5: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  llm = initialize_llm()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LLM with prompt:\n",
      "<|im_start|>system\n",
      "You are a helpful AI assistant that provides clear and concise information.<|im_end|>\n",
      "<|im_start|>user\n",
      "Write step by step the answer to 2x+3=7.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nawap Bastola\\AppData\\Local\\Temp\\ipykernel_2828\\617962864.py:21: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(full_prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, let's solve the equation \\(2x + 3 = 7\\) step by step:\n",
      "\n",
      "### Step 1: Isolate the term with the variable on one side of the equation.\n",
      "Subtract 3 from both sides:\n",
      "\\[2x + 3 - 3 = 7 - 3\\]\n",
      "This simplifies to:\n",
      "\\[2x = 4\\]\n",
      "\n",
      "### Step 2: Solve for \\(x\\) by dividing both sides by the coefficient of \\(x\\).\n",
      "Divide both sides by 2:\n",
      "\\[\\frac{2x}{2} = \\frac{4}{2}\\]\n",
      "This simplifies to:\n",
      "\\[x = 2\\]\n",
      "\n",
      "So, the solution is \\(x = 2\\)."
     ]
    }
   ],
   "source": [
    "def initialize_llm():\n",
    "    callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "    return Ollama(base_url=\"http://localhost:11434\", model=\"qwen3\", callback_manager=callback_manager)\n",
    "\n",
    "llm = initialize_llm()\n",
    "\n",
    "system_prompt = \"You are a helpful AI assistant that provides clear and concise information.\"\n",
    "user_prompt = \"Write step by step the answer to 2x+3=7.\"\n",
    "\n",
    "# Construct the full prompt using the Hugging Face format\n",
    "full_prompt = f'''<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "'''\n",
    "\n",
    "# Run the test\n",
    "print(\"Testing LLM with prompt:\")\n",
    "print(full_prompt)\n",
    "response = llm(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nawap Bastola\\AppData\\Local\\Temp\\ipykernel_2828\\942227889.py:5: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  llm = initialize_llm()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Various Image Segmentation Techniques\n",
      "\n",
      "**Thresholding Technique Segmentation**\n",
      "- Suitable for images with distinct differences between object and background. \n",
      "- Main goal: divide an image into two distinct regions (object and background) based on intensity values and properties.\n",
      "- Types: Global, Variable, Multiple.\n",
      "\n",
      "**Histogram Based Segmentation**\n",
      "- Uses the histogram of an image to separate different peaks using deep valleys.\n",
      "- Peaks in the histogram are tall, narrow, symmetric. \n",
      "- Useful for images where there is a distinct difference between object and background.\n",
      "\n",
      "**Region-Based Segmentation**\n",
      "- Segments the image into regions having similar characteristics.\n",
      "- Techniques: Region growing and region split-and-merge.\n",
      "\n",
      "**Edge-Based Segmentation**\n",
      "- Defines edges as significant changes in intensity between objects in an image.\n",
      "- Boundaries demonstrate changes between objects in images, useful when there are many objects present.\n",
      "- Unlike region-based segmentation, it is based on discontinuities or dissimilarities.\n",
      "\n",
      "**Clustering-Based Segmentation**\n",
      "- Segments the image into clusters of pixels with similar characteristics.\n",
      "- Many types available, select the best suited for a specific image processing scenario.\n",
      "\n",
      "**Texture-Based Segmentation Approaches**\n",
      "- Divides an image into regions based on texture features similarity. \n",
      "- Texture is defined as repeated patterns within objects in images.\n",
      "\n",
      "**Morphological Transforms and Filtering**\n",
      "- Morphology studies shapes and processes images through shape-based operations.\n",
      "- Basic morphological filtering includes:\n",
      "  - Erosion\n",
      "  - Dilation\n",
      "  - Opening\n",
      "  - Closing\n",
      "- Thinning reduces connected components to a single-pixel width, important for binary images only.\n",
      "\n",
      "**3D Image Processing**\n",
      "- Visualization and analysis of 3D image data through geometric transformations, filtering, and segmentation.\n",
      "- Example: processing a 3D kidney image slice (2D plane) from volumetric data.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Image segmentation techniques are diverse and effective in various applications. Thresholding, histogram-based, region-based, edge-based, clustering-based, texture-based, morphological transforms, and 3D processing all play crucial roles in enhancing image analysis and processing capabilities. Each technique addresses different aspects of image characteristics, making them indispensable tools in fields ranging from medical imaging to computer vision and beyond.\n",
      "\n",
      "These techniques vary significantly from each other in their approaches and applications but ultimately aim to improve the accuracy and efficiency of segmenting images based on their characteristics and properties."
     ]
    }
   ],
   "source": [
    "def initialize_llm():\n",
    "    callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "    return Ollama(base_url=\"http://localhost:11434\", model=\"qwen3\", callback_manager=callback_manager)\n",
    "\n",
    "llm = initialize_llm()\n",
    "text = read_file(\"samples/sample.pptx\")\n",
    "system_prompt = \"You are an expert assistant that generates structured notes from reference presentations in PDF or TXT format. Your task is to extract the key information and summarize it in a clear and organized format.\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Please summarize the provided reference text in the following format:\n",
    "\n",
    "1. For each topic, create bullet points that capture the most important information.\n",
    "2. After covering all topics, conclude by summarizing the key insights from all topics combined.\n",
    "\n",
    "Use the following structure:\n",
    "\"Heading of Topic\"\n",
    "\"Important bullet points of Topic\"\n",
    "...\n",
    "Conclusion: Summarize the entire content in a brief, insightful manner.\n",
    "\n",
    "Example:\n",
    "Text:\n",
    "AI in Healthcare\n",
    "Artificial Intelligence is revolutionizing the healthcare industry by improving diagnostics, treatment planning, and operational efficiency. Deep learning algorithms are used for medical imaging, while natural language processing (NLP) helps analyze patient data.\n",
    "\n",
    "AI in Finance\n",
    "In the financial sector, AI is applied in fraud detection, algorithmic trading, and customer service automation. Predictive analytics help identify patterns in large data sets to enhance decision-making and risk management.\n",
    "\n",
    "Ethics in AI\n",
    "As AI continues to grow, ethical considerations have become critical. Issues around privacy, data security, and bias in decision-making algorithms need to be addressed. Responsible AI development ensures fairness and accountability.\n",
    "Summary:\n",
    "AI in Healthcare\n",
    "- AI improves diagnostics, treatment planning, and operational efficiency.\n",
    "- Deep learning is used in medical imaging (e.g., MRI, CT scans).\n",
    "- NLP analyzes patient data for better insights.\n",
    "\n",
    "AI in Finance\n",
    "- AI aids in fraud detection, algorithmic trading, and customer service automation.\n",
    "- Predictive analytics enhance decision-making and risk management by identifying patterns in data.\n",
    "\n",
    "Ethics in AI\n",
    "- Critical ethical concerns include privacy, data security, and algorithmic bias.\n",
    "- Responsible AI development ensures fairness, transparency, and accountability.\n",
    "\n",
    "Conclusion\n",
    "AI is transforming multiple sectors such as healthcare and finance by enhancing efficiency and accuracy. However, ethical considerations must be addressed to ensure responsible usage, focusing on fairness and security.\n",
    "\n",
    "\n",
    "Text:\n",
    "{text}\"\"\"\n",
    "full_prompt = f'''<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "'''\n",
    "response = llm(full_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are an expert assistant that generates structured notes from reference presentations in PDF or TXT format. Your task is to extract the key information and summarize it in a clear and organized format.<|im_end|>\\n<|im_start|>user\\n\\nPlease summarize the provided reference text in the following format:\\n\\n1. For each topic, create bullet points that capture the most important information.\\n2. After covering all topics, conclude by summarizing the key insights from all topics combined.\\n\\nUse the following structure:\\n\"Heading of Topic\"\\n\"Important bullet points of Topic\"\\n...\\nConclusion: Summarize the entire content in a brief, insightful manner.\\n\\nExample:\\nText:\\nAI in Healthcare\\nArtificial Intelligence is revolutionizing the healthcare industry by improving diagnostics, treatment planning, and operational efficiency. Deep learning algorithms are used for medical imaging, while natural language processing (NLP) helps analyze patient data.\\n\\nAI in Finance\\nIn the financial sector, AI is applied in fraud detection, algorithmic trading, and customer service automation. Predictive analytics help identify patterns in large data sets to enhance decision-making and risk management.\\n\\nEthics in AI\\nAs AI continues to grow, ethical considerations have become critical. Issues around privacy, data security, and bias in decision-making algorithms need to be addressed. Responsible AI development ensures fairness and accountability.\\nSummary:\\nAI in Healthcare\\n- AI improves diagnostics, treatment planning, and operational efficiency.\\n- Deep learning is used in medical imaging (e.g., MRI, CT scans).\\n- NLP analyzes patient data for better insights.\\n\\nAI in Finance\\n- AI aids in fraud detection, algorithmic trading, and customer service automation.\\n- Predictive analytics enhance decision-making and risk management by identifying patterns in data.\\n\\nEthics in AI\\n- Critical ethical concerns include privacy, data security, and algorithmic bias.\\n- Responsible AI development ensures fairness, transparency, and accountability.\\n\\nConclusion\\nAI is transforming multiple sectors such as healthcare and finance by enhancing efficiency and accuracy. However, ethical considerations must be addressed to ensure responsible usage, focusing on fairness and security.\\n\\n\\nText:\\nVarious Image Segmentation Techniques:\\nDifferent types of Image Segmentation Techniques\\nThresholding technique segmentation\\nHistogram based segmentation\\nRegion based segmentation\\nEdge based segmentation\\nClustering based segmentation\\nMorphological Transforms and\\nTexture based segmentation approaches\\nThresholding technique segmentation\\nSegmentation algorithms based on thresholding approach are suitable for images where there is distinct difference between object and background.\\nMain Goal: divide an image into two distinct regions (object and background) directly based on intensity values and their properties\\nTypes: Global, Variable, Multiple\\n\\nOriginal coins image\\n2)Histogram based segmentation\\nHistogram of an image is a plot between intensity levels. \\nDeep valleys are used to separate different peaks of histogram. \\nHistogram peaks are tall, narrow, symmetric.\\n3) Region based Segmentation\\nThe region-based segmentation methods segments the image into various regions having similar characterizes. \\n\\nTwo Techniques: \\na. Region growing, and\\nb. Region split and merge techniques \\nWatershed \\ntransformation\\n\\n4) Edge-based segmentation \\nEdges are defined as “Sudden and Significant changes in the intensity” of an image. \\nBoundaries demonstrates changes between object in the images. \\nSignificant change in intensity between objects in the images\\nUseful when there are many objects in the images. \\nDifferent than region-based segmentation. Edge-based segmentation completely based on dissimilarities or discontinuity. \\n\\n\\n5) Clustering-based segmentation \\nThe clustering-based techniques segment the image into cluster having pixels with similar   characteristics.\\nMany types of clustering. \\nSelect the best of them that proven success rate with the image processing. \\n7) Texture based segmentation approaches\\nSegmentation based on texture characteristics consists of dividing an image into different     regions based on similarity in texture features. \\n Texture = repeated pattern of information\\nTexture image = appearance, structure, and arrangement of the parts of an object within the image. \\n6)Morphological Transforms based Segmentation \\nMorphology is study of shapes.\\nIt has a set of image processing operations that process images based on shapes and not based on pixel intensities. \\nRemember: shapes segmentations = Morphological transforms-based segmentation\\nBasic Morphological Filtering:\\nErosion\\nDilation\\nOpening\\nClosing\\nWhite Tophat\\nBlack Tophat\\nSkeletonize \\nConvex Hull\\n\\nDifferent types of Morphological Filtering\\nSkeleton and Convex hull method: \\nThe convex skull of a polygon is the largest convex polygon contained inside it. It can be found in polynomial time, but the exponent of the algorithm is high.\\nThinning is used to reduce each connected component in a binary image to a single-pixel wide skeleton. It is important to note that this is performed on binary images only.\\nInteraction with 3D images\\n3D image processing is the visualization, processing, and analysis of 3D image data through geometric transformations, filtering, image segmentation, and other morphological operations.\\n3D kidney image\\n\\xa0A slice (2D plane) of the 3D data Kidney image\\n# Animation frames from 3D images \\n3D animation creates moving images in a 3D environment, giving digital objects the illusion of motion through 3D space.\\nTensor Structure computation  of 3D images \\nIn the context of volumetric (3D) image analysis, a structure tensor is a 3-by-3 matrix which summarizes orientation in a certain neighborhood around a certain point.\\nLet’s Go to Exercise ……<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Question 1:** What technique divides an image into two distinct regions based on intensity values?  \n",
      "**A.** Histogram-based segmentation  \n",
      "**B.** Edge-based segmentation  \n",
      "**C.** Clustering-based segmentation  \n",
      "**D.** Thresholding technique segmentation  \n",
      "**Correct Answer:** D\n",
      "\n",
      "**Question 2:** Which of the following is NOT a type of region-based segmentation?  \n",
      "**A.** Watershed transformation  \n",
      "**B.** Region growing  \n",
      "**C.** Region split and merge techniques  \n",
      "**D.** Edge detection  \n",
      "**Correct Answer:** D\n",
      "\n",
      "**Question 3:** What is the main goal of histogram based segmentation?  \n",
      "**A.** To divide an image into two distinct regions (object and background) directly based on intensity values and their properties  \n",
      "**B.** To separate different peaks in the histogram using deep valleys  \n",
      "**C.** To create a binary image by thresholding intensities  \n",
      "**D.** To merge multiple regions into one large area  \n",
      "**Correct Answer:** B\n",
      "\n",
      "**Question 4:** What is the significance of edges in edge-based segmentation?  \n",
      "**A.** Edges are significant changes in intensity between objects in an image, and they help identify boundaries.  \n",
      "**B.** Edges represent changes in color only, not intensity.  \n",
      "**C.** Edges show similarities between different regions in images.  \n",
      "**D.** Edges are irrelevant in segmentation processes.  \n",
      "**Correct Answer:** A\n",
      "\n",
      "**Question 5:** Which technique segments the image into clusters with pixels having similar characteristics?  \n",
      "**A.** Thresholding technique segmentation  \n",
      "**B.** Clustering-based segmentation  \n",
      "**C.** Region based Segmentation  \n",
      "**D.** Edge-based segmentation  \n",
      "**Correct Answer:** B"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are a highly knowledgeable assistant specializing in generating educational multiple-choice questions (MCQs) from provided reference material. Your goal is to analyze key points, extract essential information, and create five multiple-choice questions. Each question must be well-structured, clear, and relevant to the text, with one correct answer and three plausible distractors. The focus should be on assessing comprehension, critical thinking, and retention of the material.\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Please create five multiple-choice questions from the provided reference text. Each question should have one correct answer and three incorrect options.\n",
    "Strucutre:\n",
    "**Question**  \n",
    "**A.** Option 1  \n",
    "**B.** Option 2  \n",
    "**C.** Option 3  \n",
    "**D.** Option 4  \n",
    "**Correct Answer:** A/B/C/D\n",
    "\n",
    "Example:\n",
    "**Question 1:** What is the capital of France?  \n",
    "**A.** Berlin  \n",
    "**B.** Madrid  \n",
    "**C.** Paris  \n",
    "**D.** Rome  \n",
    "**Correct Answer:** C\n",
    "Ensure that the questions are clear and concise, and that options are straightforward without excessive detail or ambiguity.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "full_prompt = f'''<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "'''\n",
    "raw_response = llm(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an expert assistant that creates multiple-choice questions (MCQs) from provided reference material. Extract key information and generate five MCQs, each with one correct answer and three incorrect options.\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Please create five multiple-choice questions from the reference text in JSON format. Each question should have one correct answer and three incorrect options. Use the following structure:\n",
    "\n",
    "[\n",
    "    {{\n",
    "        \"question\": \"Question 1 text...\",\n",
    "        \"options\": [\"Option A\", \"Option B\", \"Option C\", \"Option D\"],\n",
    "        \"correct_option\": \"Option A\"\n",
    "    }}\n",
    "]\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "[\n",
    "    {{\n",
    "        \"question\": \"What is the capital of France?\",\n",
    "        \"options\": [\"Berlin\", \"Madrid\", \"Paris\", \"Rome\"],\n",
    "        \"correct_option\": \"Paris\"\n",
    "    }}\n",
    "]\n",
    "\n",
    "Ensure that the questions are clear and concise, and that options are straightforward without excessive detail or ambiguity.\n",
    "\n",
    "Text:\n",
    "{raw_response}\n",
    "\"\"\"\n",
    "\n",
    "full_prompt = f'''<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "    {\n",
      "        \"question\": \"What technique divides an image into two distinct regions based on intensity values?\",\n",
      "        \"options\": [\"Histogram-based segmentation\", \"Edge-based segmentation\", \"Clustering-based segmentation\", \"Thresholding technique segmentation\"],\n",
      "        \"correct_option\": \"Thresholding technique segmentation\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"Which of the following is NOT a type of region-based segmentation?\",\n",
      "        \"options\": [\"Watershed transformation\", \"Region growing\", \"Region split and merge techniques\", \"Edge detection\"],\n",
      "        \"correct_option\": \"Edge detection\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the main goal of histogram based segmentation?\",\n",
      "        \"options\": [\"To divide an image into two distinct regions (object and background) directly based on intensity values and their properties\", \"To separate different peaks in the histogram using deep valleys\", \"To create a binary image by thresholding intensities\", \"To merge multiple regions into one large area\"],\n",
      "        \"correct_option\": \"To separate different peaks in the histogram using deep valleys\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the significance of edges in edge-based segmentation?\",\n",
      "        \"options\": [\"Edges are significant changes in intensity between objects in an image, and they help identify boundaries\", \"Edges represent changes in color only, not intensity\", \"Edges show similarities between different regions in images\", \"Edges are irrelevant in segmentation processes\"],\n",
      "        \"correct_option\": \"Edges are significant changes in intensity between objects in an image, and they help identify boundaries\"\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"Which technique segments the image into clusters with pixels having similar characteristics?\",\n",
      "        \"options\": [\"Thresholding technique segmentation\", \"Clustering-based segmentation\", \"Region based Segmentation\", \"Edge-based segmentation\"],\n",
      "        \"correct_option\": \"Clustering-based segmentation\"\n",
      "    }\n",
      "]\n",
      "```"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'```json\\n[\\n    {\\n        \"question\": \"What technique divides an image into two distinct regions based on intensity values?\",\\n        \"options\": [\"Histogram-based segmentation\", \"Edge-based segmentation\", \"Clustering-based segmentation\", \"Thresholding technique segmentation\"],\\n        \"correct_option\": \"Thresholding technique segmentation\"\\n    },\\n    {\\n        \"question\": \"Which of the following is NOT a type of region-based segmentation?\",\\n        \"options\": [\"Watershed transformation\", \"Region growing\", \"Region split and merge techniques\", \"Edge detection\"],\\n        \"correct_option\": \"Edge detection\"\\n    },\\n    {\\n        \"question\": \"What is the main goal of histogram based segmentation?\",\\n        \"options\": [\"To divide an image into two distinct regions (object and background) directly based on intensity values and their properties\", \"To separate different peaks in the histogram using deep valleys\", \"To create a binary image by thresholding intensities\", \"To merge multiple regions into one large area\"],\\n        \"correct_option\": \"To separate different peaks in the histogram using deep valleys\"\\n    },\\n    {\\n        \"question\": \"What is the significance of edges in edge-based segmentation?\",\\n        \"options\": [\"Edges are significant changes in intensity between objects in an image, and they help identify boundaries\", \"Edges represent changes in color only, not intensity\", \"Edges show similarities between different regions in images\", \"Edges are irrelevant in segmentation processes\"],\\n        \"correct_option\": \"Edges are significant changes in intensity between objects in an image, and they help identify boundaries\"\\n    },\\n    {\\n        \"question\": \"Which technique segments the image into clusters with pixels having similar characteristics?\",\\n        \"options\": [\"Thresholding technique segmentation\", \"Clustering-based segmentation\", \"Region based Segmentation\", \"Edge-based segmentation\"],\\n        \"correct_option\": \"Clustering-based segmentation\"\\n    }\\n]\\n```'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Thank you for providing such detailed information about Long Short-Term Memory (LSTM), Gated Recurrent Units (GRU), and related topics. Let's break down the key points:\n",
      "\n",
      "### LSTM Overview\n",
      "\n",
      "**Architecture:**\n",
      "- **Memory Cell:** The core component of LSTM, it stores memory over time.\n",
      "- **Gates:**\n",
      "  - **Input Gate (I):** Controls what new information is added to the cell state.\n",
      "  - **Output Gate (O):** Determines how much of the cell state should be output.\n",
      "  - **Forget Gate (F):** Decides which parts of the cell state are discarded.\n",
      "\n",
      "- **Nonlinearities:** Use Sigmoid and Tanh functions for controlling the gates, ensuring they produce values between 0 and 1.\n",
      "- **Cell State Update:**\n",
      "  \\[\n",
      "  C_t = f(C_{t-1}, X_t) + i(W_x X_t)\n",
      "  \\]\n",
      "  where:\n",
      "  - \\(C_{t-1}\\) is the previous cell state.\n",
      "  - \\(X_t\\) is the input vector at time t.\n",
      "  - \\(W_x\\) are weights.\n",
      "  - \\(i\\) (input gate value) controls which parts of \\(X_t\\) to add to \\(C_{t-1}\\).\n",
      "  \n",
      "- **Output:**\n",
      "  \\[\n",
      "  O = \\sigma(W_o [h, C])\n",
      "  \\]\n",
      "  where:\n",
      "  - \\(W_o\\) are weights.\n",
      "  - \\(h\\) is the hidden state.\n",
      "  - \\(\\sigma\\) is a sigmoid function.\n",
      "\n",
      "### LSTM Limitations\n",
      "1. **Long-Term Dependency Problem:** LSTM struggles with sequences of very long length.\n",
      "2. **Complexity and Parameter Increase:** More gates mean more parameters, leading to longer convergence times and higher computational requirements.\n",
      "3. **Indexed Data Storage:** Unlike indexed structures like lists or structured data, LSTM cannot store information in a way that allows for efficient retrieval.\n",
      "\n",
      "### Comparison: GRU vs LSTM\n",
      "- **Gated Recurrent Units (GRU):**\n",
      "  - Only uses two gates: Reset Gate (\\(R\\)) and Update Gate (\\(U\\)).\n",
      "  - Simplifies the architecture compared to LSTM.\n",
      "  - Less parameters, faster execution, trains faster but can be less accurate on longer sequences.\n",
      "\n",
      "### CNN + RNN for Image Captioning\n",
      "- **CNN (Convolutional Neural Network):**\n",
      "  - Extracts features from images.\n",
      "- **RNN (Recurrent Neural Network):**\n",
      "  - Captures the temporal dynamics of captions or descriptions.\n",
      "  - Combines image and text information to generate accurate captions.\n",
      "\n",
      "### Time Series Models\n",
      "- **Auto-Covariance and Yule-Walker Equations:**\n",
      "  Used for modeling time series data.\n",
      "- **Exponential Smoothing:** A method for smoothing out noise in a dataset.\n",
      "- **Partial Autocorrelation (PACF) and PACF Function:** Useful for understanding dependencies between variables.\n",
      "- **Auto-Correlation (ACF):** Measures the correlation between a variable and its lagged values.\n",
      "\n",
      "### AR, MA, ARMA, ARIMA Models\n",
      "- **AR (Auto-Regressive Model):**\n",
      "  - Focuses on past values of the series.\n",
      "- **MA (Moving Average Model):**\n",
      "  - Uses randomness or noise as a source of variation.\n",
      "- **ARMA:**\n",
      "  - Combines both AR and MA components.\n",
      "- **ARIMA:**\n",
      "  - Adds differencing to make data stationary before applying ARMA models.\n",
      "- **SARIMA (Seasonal ARIMA):**\n",
      "  - Accounts for seasonality in time series.\n",
      "\n",
      "### Conclusion\n",
      "LSTM is powerful but comes with limitations. GRU offers a simpler alternative that might be more suitable for certain tasks, especially when dealing with long sequences. CNN + RNNs are useful for applications where both image and text information need to be integrated. Understanding these models and their characteristics can help in choosing the right approach for specific problems.\n",
      "\n",
      "---\n",
      "\n",
      "If you have any more questions or need further details on any of these topics, feel free to ask! Sure, let's break down the information you've provided and provide some additional context and details about LSTM, GRU, CNN-RNN for image captioning, and other related concepts.\n",
      "\n",
      "### Long Short-Term Memory (LSTM)\n",
      "\n",
      "**Concept Overview:**\n",
      "- **Neuron Structure:** LSTMs consist of a single cell that processes sequences over time.\n",
      "- **Gates:** Three main gates control the flow of information:\n",
      "  - **Input Gate (`i`):** Controls what new information is added to the memory cell.\n",
      "  - **Forget Gate (`f`):** Determines which parts of the previous memory should be discarded.\n",
      "  - **Output Gate (`o`):** Outputs the final state from the cell.  \n",
      "- **Memory Cell:** Stores and updates its content over time based on these gates.\n",
      "\n",
      "**Operations:**\n",
      "- `Ct = f * Ct-1 + i * tanh(Vx)` (Forget and Input)\n",
      "- `Ot = o * tanh(Ct)` (Output)\n",
      "\n",
      "### Comparison of LSTM vs GRU\n",
      "\n",
      "- **Gates:** \n",
      "  - **LSTM:** Three gates (`i`, `f`, `o`).\n",
      "  - **GRU:** Two gates: Reset Gate (`r`) and Update Gate (`u`).\n",
      "\n",
      "- **Complexity & Memory Usage:**\n",
      "  - **LSTM:** More complex due to three gates, leading to increased parameters and potential slower training.\n",
      "  - **GRU:** Simpler with two gates, uses fewer parameters, executes faster, and trains faster.\n",
      "\n",
      "### CNN-RNN for Image Captioning\n",
      "\n",
      "**CNN-RNN Architecture:**\n",
      "\n",
      "1. **Convolutional Neural Network (CNN):**\n",
      "   - Extracts spatial features from images.\n",
      "2. **Recurrent Neural Network (RNN):**\n",
      "   - Processes the sequence of features over time to generate captions.\n",
      "3. **Bidirectional RNN:** Combines information from both directions, enhancing understanding.\n",
      "\n",
      "**Key Components:**\n",
      "\n",
      "- **Image Captioning Model:**\n",
      "  - The CNN generates a fixed-length feature vector for each image.\n",
      "  - A BiLSTM (Bidirectional LSTM) processes these vectors sequentially to produce the final caption.\n",
      "  \n",
      "### Comparison with GRU\n",
      "\n",
      "- **Performance on Long Sequences:** \n",
      "  - **GRU:** Can handle longer sequences well due to its simpler architecture and fewer parameters.\n",
      "\n",
      "### Time-Series Models\n",
      "\n",
      "**Models:**\n",
      "\n",
      "1. **Auto-Covariance & Yule-Walker Equations**\n",
      "2. **Exponential Smoothing**\n",
      "3. **Partial Autocorrelation (PACF)**\n",
      "4. **Autocorrelation (ACF)**\n",
      "5. **AR Model (Auto-Regressive)**\n",
      "6. **MA Model (Moving Average)**\n",
      "7. **ARMA Model (Auto-Regressive Moving Average)**\n",
      "8. **ARIMA Model (AutoRegressive Integrated Moving Average)**\n",
      "9. **SARIMA Model (Seasonal ARIMA)**\n",
      "10. **ARIMA with Exogenous Variables**\n",
      "\n",
      "**Applications:**\n",
      "- Forecasting and time series analysis.\n",
      "\n",
      "### Contact Information\n",
      "\n",
      "If you need any more detailed information or assistance, feel free to ask!\n",
      "\n",
      "---\n",
      "\n",
      "Feel free to clarify or expand on specific points if needed! [\n",
      "        {\n",
      "            \"question\": \"What are the three main gates in an LSTM cell used for controlling the flow of information?\",\n",
      "            \"options\": [\n",
      "                \"Input Gate (`i`), Reset Gate (`r`), Output Gate (`o`)\",\n",
      "                \"Reset Gate (`r`), Update Gate (`u`), Memory Gate (`m`)\",\n",
      "                \"Forget Gate (`f`), Input Gate (`i`), Output Gate (`o`)\",\n",
      "                \"Memory Cell, Forget Gate (`f`), Input Gate (`i`)\"\n",
      "            ],\n",
      "            \"correct_option\": \"Forget Gate (`f`), Input Gate (`i`), Output Gate (`o`)\"\n",
      "        },\n",
      "        {\n",
      "            \"question\": \"In comparison to GRU, what is a key advantage of using LSTM in terms of parameter usage?\",\n",
      "            \"options\": [\n",
      "                \"LSTM uses fewer parameters\",\n",
      "                \"GRU uses fewer parameters\",\n",
      "                \"Both have the same number of parameters\",\n",
      "                \"No difference in parameter usage\"\n",
      "            ],\n",
      "            \"correct_option\": \"GRU uses fewer parameters\"\n",
      "        },\n",
      "        {\n",
      "            \"question\": \"What is the primary function of a BiLSTM in the context of image captioning?\",\n",
      "            \"options\": [\n",
      "                \"To extract spatial features from images\",\n",
      "                \"To generate fixed-length feature vectors for each image\",\n",
      "                \"To process sequences of features over time to produce captions\",\n",
      "                \"To enhance understanding by combining information from both directions\"\n",
      "            ],\n",
      "            \"correct_option\": \"To process sequences of features over time to produce captions\"\n",
      "        },\n",
      "        {\n",
      "            \"question\": \"Which model is known for handling longer sequences more effectively compared to GRU?\",\n",
      "            \"options\": [\n",
      "                \"LSTM\",\n",
      "                \"GRU\",\n",
      "                \"Both have the same ability to handle long sequences\",\n",
      "                \"Neither handles long sequences well\"\n",
      "            ],\n",
      "            \"correct_option\": \"LSTM\"\n",
      "        },\n",
      "        {\n",
      "            \"question\": \"In time-series analysis, which model is commonly used for forecasting and analyzing data over a series of time steps?\",\n",
      "            \"options\": [\n",
      "                \"AR Model (Auto-Regressive)\",\n",
      "                \"MA Model (Moving Average)\",\n",
      "                \"Both AR Model and MA Model\",\n",
      "                \"None of the above\"\n",
      "            ],\n",
      "            \"correct_option\": \"Both AR Model and MA Model\"\n",
      "        }\n",
      "    ]"
     ]
    }
   ],
   "source": [
    "from model import extract_json\n",
    "extracted_json = extract_json(\"samples/sample.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "final = json.loads(extracted_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What are the three main gates in an LSTM cell used for controlling the flow of information?',\n",
       "  'options': ['Input Gate (`i`), Reset Gate (`r`), Output Gate (`o`)',\n",
       "   'Reset Gate (`r`), Update Gate (`u`), Memory Gate (`m`)',\n",
       "   'Forget Gate (`f`), Input Gate (`i`), Output Gate (`o`)',\n",
       "   'Memory Cell, Forget Gate (`f`), Input Gate (`i`)'],\n",
       "  'correct_option': 'Forget Gate (`f`), Input Gate (`i`), Output Gate (`o`)'},\n",
       " {'question': 'In comparison to GRU, what is a key advantage of using LSTM in terms of parameter usage?',\n",
       "  'options': ['LSTM uses fewer parameters',\n",
       "   'GRU uses fewer parameters',\n",
       "   'Both have the same number of parameters',\n",
       "   'No difference in parameter usage'],\n",
       "  'correct_option': 'GRU uses fewer parameters'},\n",
       " {'question': 'What is the primary function of a BiLSTM in the context of image captioning?',\n",
       "  'options': ['To extract spatial features from images',\n",
       "   'To generate fixed-length feature vectors for each image',\n",
       "   'To process sequences of features over time to produce captions',\n",
       "   'To enhance understanding by combining information from both directions'],\n",
       "  'correct_option': 'To process sequences of features over time to produce captions'},\n",
       " {'question': 'Which model is known for handling longer sequences more effectively compared to GRU?',\n",
       "  'options': ['LSTM',\n",
       "   'GRU',\n",
       "   'Both have the same ability to handle long sequences',\n",
       "   'Neither handles long sequences well'],\n",
       "  'correct_option': 'LSTM'},\n",
       " {'question': 'In time-series analysis, which model is commonly used for forecasting and analyzing data over a series of time steps?',\n",
       "  'options': ['AR Model (Auto-Regressive)',\n",
       "   'MA Model (Moving Average)',\n",
       "   'Both AR Model and MA Model',\n",
       "   'None of the above'],\n",
       "  'correct_option': 'Both AR Model and MA Model'}]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
