{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "from load import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Vectorstore Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nawap Bastola\\AppData\\Local\\Temp\\ipykernel_26300\\609789627.py:9: DeprecationWarning: callback_manager is deprecated. Please use callbacks instead.\n",
      "  chat_model = initialize_chat_ollama()\n"
     ]
    }
   ],
   "source": [
    "def initialize_chat_ollama():\n",
    "    callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "    return ChatOllama(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model=\"qwen3\",\n",
    "        temperature=0.5,\n",
    "        callback_manager=callback_manager\n",
    "    )\n",
    "chat_model = initialize_chat_ollama()\n",
    "\n",
    "# Initialize Ollama Embeddings\n",
    "def initialize_embeddings():\n",
    "    return OllamaEmbeddings(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model=\"qwen3\"\n",
    "    )\n",
    "embeddings = initialize_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Funcions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(file_paths):\n",
    "    documents = []\n",
    "    for file_path in file_paths:\n",
    "        content = read_file(file_path)\n",
    "        documents.append(Document(page_content=content, metadata={\"source\": file_path}))\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    return text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(documents, embeddings):\n",
    "    return Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rag_chain_with_memory(chat_model, vector_store):\n",
    "    system_template = \"<|im_start|>system\\nYou are a helpful AI assistant that provides clear and concise information based on the given context and chat history.<|im_end|>\"\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "    human_template = \"<|im_start|>user\\nContext: {context}\\nChat History: {chat_history}\\nQuestion: {question}<|im_end|>\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "    assistant_template = \"<|im_start|>assistant\\n\"\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        system_message_prompt,\n",
    "        human_message_prompt,\n",
    "        assistant_template\n",
    "    ])\n",
    "\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "    return ConversationalRetrievalChain.from_llm(\n",
    "        llm=chat_model,\n",
    "        retriever=vector_store.as_retriever(),\n",
    "        memory=memory,\n",
    "        combine_docs_chain_kwargs={\"prompt\": chat_prompt}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking if Qwen's Embeddings work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ChatOllama with prompt:\n",
      "<|im_start|>system\n",
      "You are a helpful AI assistant that provides clear and concise information.<|im_end|>\n",
      "<|im_start|>user\n",
      "Write step by step the answer to 2x+3=7.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "Certainly! Here is a step-by-step guide to solving the equation \\(2x + 3 = 7\\):\n",
      "\n",
      "### Step 1: Subtract 3 from both sides of the equation.\n",
      "This step aims to isolate the term containing the variable on one side of the equation.\n",
      "\n",
      "\\[2x + 3 - 3 = 7 - 3\\]\n",
      "\n",
      "Simplifying this, we get:\n",
      "\n",
      "\\[2x = 4\\]\n",
      "\n",
      "### Step 2: Divide both sides by 2.\n",
      "This step isolates \\(x\\) and gives us its value.\n",
      "\n",
      "\\[\\frac{2x}{2} = \\frac{4}{2}\\]\n",
      "\n",
      "Simplifying this, we get:\n",
      "\n",
      "\\[x = 2\\]\n",
      "\n",
      "So the solution to the equation \\(2x + 3 = 7\\) is \\(x = 2\\).\n",
      "ChatOllama Response:\n",
      "Certainly! Here is a step-by-step guide to solving the equation \\(2x + 3 = 7\\):\n",
      "\n",
      "### Step 1: Subtract 3 from both sides of the equation.\n",
      "This step aims to isolate the term containing the variable on one side of the equation.\n",
      "\n",
      "\\[2x + 3 - 3 = 7 - 3\\]\n",
      "\n",
      "Simplifying this, we get:\n",
      "\n",
      "\\[2x = 4\\]\n",
      "\n",
      "### Step 2: Divide both sides by 2.\n",
      "This step isolates \\(x\\) and gives us its value.\n",
      "\n",
      "\\[\\frac{2x}{2} = \\frac{4}{2}\\]\n",
      "\n",
      "Simplifying this, we get:\n",
      "\n",
      "\\[x = 2\\]\n",
      "\n",
      "So the solution to the equation \\(2x + 3 = 7\\) is \\(x = 2\\).\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful AI assistant that provides clear and concise information.\"\n",
    "user_prompt = \"Write step by step the answer to 2x+3=7.\"\n",
    "full_prompt = f'''<|im_start|>system\n",
    "{system_prompt}<|im_end|>\n",
    "<|im_start|>user\n",
    "{user_prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "'''\n",
    "print(\"Testing ChatOllama with prompt:\")\n",
    "print(full_prompt)\n",
    "response = chat_model.predict(full_prompt)\n",
    "print(\"\\nChatOllama Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\"samples/sample.pptx\", \"samples/sample.txt\"]\n",
    "documents = load_documents(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'samples/sample.pptx'}, page_content='Various Image Segmentation Techniques:\\nDifferent types of Image Segmentation Techniques\\nThresholding technique segmentation\\nHistogram based segmentation\\nRegion based segmentation\\nEdge based segmentation\\nClustering based segmentation\\nMorphological Transforms and\\nTexture based segmentation approaches\\nThresholding technique segmentation\\nSegmentation algorithms based on thresholding approach are suitable for images where there is distinct difference between object and background.\\nMain Goal: divide an image into two distinct regions (object and background) directly based on intensity values and their properties\\nTypes: Global, Variable, Multiple'),\n",
       " Document(metadata={'source': 'samples/sample.pptx'}, page_content='Original coins image\\n2)Histogram based segmentation\\nHistogram of an image is a plot between intensity levels. \\nDeep valleys are used to separate different peaks of histogram. \\nHistogram peaks are tall, narrow, symmetric.\\n3) Region based Segmentation\\nThe region-based segmentation methods segments the image into various regions having similar characterizes. \\n\\nTwo Techniques: \\na. Region growing, and\\nb. Region split and merge techniques \\nWatershed \\ntransformation\\n\\n4) Edge-based segmentation \\nEdges are defined as “Sudden and Significant changes in the intensity” of an image. \\nBoundaries demonstrates changes between object in the images. \\nSignificant change in intensity between objects in the images\\nUseful when there are many objects in the images. \\nDifferent than region-based segmentation. Edge-based segmentation completely based on dissimilarities or discontinuity.'),\n",
       " Document(metadata={'source': 'samples/sample.pptx'}, page_content='5) Clustering-based segmentation \\nThe clustering-based techniques segment the image into cluster having pixels with similar   characteristics.\\nMany types of clustering. \\nSelect the best of them that proven success rate with the image processing. \\n7) Texture based segmentation approaches\\nSegmentation based on texture characteristics consists of dividing an image into different     regions based on similarity in texture features. \\n Texture = repeated pattern of information\\nTexture image = appearance, structure, and arrangement of the parts of an object within the image. \\n6)Morphological Transforms based Segmentation \\nMorphology is study of shapes.\\nIt has a set of image processing operations that process images based on shapes and not based on pixel intensities. \\nRemember: shapes segmentations = Morphological transforms-based segmentation\\nBasic Morphological Filtering:\\nErosion\\nDilation\\nOpening\\nClosing\\nWhite Tophat\\nBlack Tophat\\nSkeletonize \\nConvex Hull'),\n",
       " Document(metadata={'source': 'samples/sample.pptx'}, page_content='Different types of Morphological Filtering\\nSkeleton and Convex hull method: \\nThe convex skull of a polygon is the largest convex polygon contained inside it. It can be found in polynomial time, but the exponent of the algorithm is high.\\nThinning is used to reduce each connected component in a binary image to a single-pixel wide skeleton. It is important to note that this is performed on binary images only.\\nInteraction with 3D images\\n3D image processing is the visualization, processing, and analysis of 3D image data through geometric transformations, filtering, image segmentation, and other morphological operations.\\n3D kidney image\\n\\xa0A slice (2D plane) of the 3D data Kidney image\\n# Animation frames from 3D images \\n3D animation creates moving images in a 3D environment, giving digital objects the illusion of motion through 3D space.\\nTensor Structure computation  of 3D images \\nIn the context of volumetric (3D) image analysis, a structure tensor is a 3-by-3 matrix which summarizes orientation in a certain neighborhood around a certain point.\\nLet’s Go to Exercise ……'),\n",
       " Document(metadata={'source': 'samples/sample.txt'}, page_content='Introduction:\\nThis is a sample document created for testing the file reading function. It contains various sections and some sample content to ensure that the function works as expected.\\n\\nSection 1: Overview\\n- This section provides a brief overview of the document.\\n- It explains the purpose of the document and what it aims to achieve.\\n\\nSection 2: Features\\n- Feature 1: Reading text files.\\n- Feature 2: Reading PDF files.\\n- Feature 3: Reading PowerPoint files.\\n\\nSection 3: Implementation\\n- The implementation involves using different libraries to handle each file type.\\n- For text files, the built-in `open` function is used.\\n- For PDF files, the `PyPDF2` library is used.\\n- For PowerPoint files, the `python-pptx` library is used.\\n\\nConclusion:\\nThis document has provided a sample structure and content to test the file reading function. By ensuring that the function can handle different file types, we can verify its robustness and reliability.\\n\\nThank you for using this sample document!')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Clustering-based segmentation techniques and their effectiveness for image processing.\n",
      "- Types of clustering methods, with a focus on selecting the best proven to work well with image processing.\n",
      "- Texture-based segmentation approaches, explaining how texture features help divide images into regions with similar characteristics.\n",
      "- Morphological transforms-based segmentation, detailing operations like erosion, dilation, opening, closing, white and black tophat, skeletonize, and convex hull, which process images based on shapes rather than pixel intensities.\n",
      "RAG Query: What are the topics discussed in these documents? Write it in points\n",
      "RAG Response:\n",
      "- Clustering-based segmentation techniques and their effectiveness for image processing.\n",
      "- Types of clustering methods, with a focus on selecting the best proven to work well with image processing.\n",
      "- Texture-based segmentation approaches, explaining how texture features help divide images into regions with similar characteristics.\n",
      "- Morphological transforms-based segmentation, detailing operations like erosion, dilation, opening, closing, white and black tophat, skeletonize, and convex hull, which process images based on shapes rather than pixel intensities.\n"
     ]
    }
   ],
   "source": [
    "vector_store = create_vector_store(documents, embeddings)\n",
    "\n",
    "rag_chain = create_rag_chain(chat_model, vector_store)\n",
    "\n",
    "rag_query = \"What are the topics discussed in these documents? Write it in points\"\n",
    "rag_response = rag_chain.run(rag_query)\n",
    "print(f\"\\nRAG Query: {rag_query}\")\n",
    "print(f\"RAG Response:\\n{rag_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 1: <|im_start|>What is the main topic of the documents?<|im_end|>\n",
      "The main topics of these documents are related to testing a file reading function. The documents provide various sections such as overview, features, implementation details, and conclusions that all revolve around ensuring the functionality of a file reading test framework.Response 1: The main topics of these documents are related to testing a file reading function. The documents provide various sections such as overview, features, implementation details, and conclusions that all revolve around ensuring the functionality of a file reading test framework.\n",
      "\n",
      "Query 2: <|im_start|>Can you provide more details about that?<|im_end|>\n",
      " Can you provide more details about the main topics of these documents related to testing a file reading function?Certainly! Here are more detailed breakdowns of the main topics in the documents:\n",
      "\n",
      "1. **Overview**:\n",
      "   - Purpose and scope of the document (testing a file reading function).\n",
      "   - Explanation of what is being tested, including specific file types (text files, PDF files, PowerPoint files).\n",
      "\n",
      "2. **Features**:\n",
      "   - Detailed explanation of each feature (reading text files, reading PDF files, reading PowerPoint files).\n",
      "   - Specific examples or sample content for each feature.\n",
      "   - Clarification on how these features are implemented.\n",
      "\n",
      "3. **Implementation**:\n",
      "   - Description of the libraries used to handle different file types (built-in `open` function for text files, `PyPDF2` library for PDF files, `python-pptx` library for PowerPoint files).\n",
      "   - Code snippets or pseudo-code demonstrating the implementation.\n",
      "   - Explanation of how each feature is implemented using these libraries.\n",
      "\n",
      "4. **Conclusion**:\n",
      "   - Summary of what has been tested (file reading functionality across different file types).\n",
      "   - Confirmation that robustness and reliability have been verified through testing.\n",
      "   - Final note thanking users for their use of the document.\n",
      "\n",
      "Each section works together to comprehensively test and validate the file reading function, providing a structured approach to ensure its effectiveness.Response 2: Certainly! Here are more detailed breakdowns of the main topics in the documents:\n",
      "\n",
      "1. **Overview**:\n",
      "   - Purpose and scope of the document (testing a file reading function).\n",
      "   - Explanation of what is being tested, including specific file types (text files, PDF files, PowerPoint files).\n",
      "\n",
      "2. **Features**:\n",
      "   - Detailed explanation of each feature (reading text files, reading PDF files, reading PowerPoint files).\n",
      "   - Specific examples or sample content for each feature.\n",
      "   - Clarification on how these features are implemented.\n",
      "\n",
      "3. **Implementation**:\n",
      "   - Description of the libraries used to handle different file types (built-in `open` function for text files, `PyPDF2` library for PDF files, `python-pptx` library for PowerPoint files).\n",
      "   - Code snippets or pseudo-code demonstrating the implementation.\n",
      "   - Explanation of how each feature is implemented using these libraries.\n",
      "\n",
      "4. **Conclusion**:\n",
      "   - Summary of what has been tested (file reading functionality across different file types).\n",
      "   - Confirmation that robustness and reliability have been verified through testing.\n",
      "   - Final note thanking users for their use of the document.\n",
      "\n",
      "Each section works together to comprehensively test and validate the file reading function, providing a structured approach to ensure its effectiveness.\n",
      "\n",
      "Query 3: <|im_start|>How does this relate to the previous information you gave me?<|im_end|>\n",
      " How do these details relate to the previous information provided about testing a file reading function in the documents?These detailed breakdowns relate directly to the previously provided information about testing a file reading function by addressing each aspect systematically:\n",
      "\n",
      "1. **Overview**:\n",
      "   - Provides context and purpose of the document.\n",
      "   - Clarifies what is being tested (file reading function) with specific details on file types (text, PDF, PowerPoint).\n",
      "\n",
      "2. **Features**:\n",
      "   - Breaks down each feature into more detail.\n",
      "   - Includes sample content or examples for each feature to ensure that functionality is tested correctly.\n",
      "\n",
      "3. **Implementation**:\n",
      "   - Provides the technical implementation of features using libraries (`open`, `PyPDF2`, `python-pptx`).\n",
      "   - Offers code snippets or pseudo-code to illustrate how these implementations work in practice.\n",
      "   \n",
      "4. **Conclusion**:\n",
      "   - Summarizes the testing process and results.\n",
      "   - Ensures that robustness and reliability have been confirmed through thorough testing.\n",
      "\n",
      "By breaking down each section, it ensures a comprehensive test of the file reading function across different file types, providing clear paths for validation and verification. This structured approach helps in identifying any potential issues or areas needing improvement in the implementation.\n",
      "\n",
      "Overall, these detailed breakdowns ensure that every aspect of the document aligns with the goal of testing a robust and reliable file reading function.Response 3: These detailed breakdowns relate directly to the previously provided information about testing a file reading function by addressing each aspect systematically:\n",
      "\n",
      "1. **Overview**:\n",
      "   - Provides context and purpose of the document.\n",
      "   - Clarifies what is being tested (file reading function) with specific details on file types (text, PDF, PowerPoint).\n",
      "\n",
      "2. **Features**:\n",
      "   - Breaks down each feature into more detail.\n",
      "   - Includes sample content or examples for each feature to ensure that functionality is tested correctly.\n",
      "\n",
      "3. **Implementation**:\n",
      "   - Provides the technical implementation of features using libraries (`open`, `PyPDF2`, `python-pptx`).\n",
      "   - Offers code snippets or pseudo-code to illustrate how these implementations work in practice.\n",
      "   \n",
      "4. **Conclusion**:\n",
      "   - Summarizes the testing process and results.\n",
      "   - Ensures that robustness and reliability have been confirmed through thorough testing.\n",
      "\n",
      "By breaking down each section, it ensures a comprehensive test of the file reading function across different file types, providing clear paths for validation and verification. This structured approach helps in identifying any potential issues or areas needing improvement in the implementation.\n",
      "\n",
      "Overall, these detailed breakdowns ensure that every aspect of the document aligns with the goal of testing a robust and reliable file reading function.\n"
     ]
    }
   ],
   "source": [
    "rag_chain = create_rag_chain_with_memory(chat_model, vector_store)\n",
    "\n",
    "queries = [\n",
    "    \"<|im_start|>What is the main topic of the documents?<|im_end|>\",\n",
    "    \"<|im_start|>Can you provide more details about that?<|im_end|>\",\n",
    "    \"<|im_start|>How does this relate to the previous information you gave me?<|im_end|>\"\n",
    "]\n",
    "\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"\\nQuery {i}: {query}\")\n",
    "    response = rag_chain({\"question\": query})\n",
    "    print(f\"Response {i}: {response['answer']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
